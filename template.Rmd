---
title: "Super Awesome Project Template"
output: word_document
names: "Caleb Bekkum, Luke Spika, Cole Umland, Charlie Wiegel"
date: "2025-04-11"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Section 1
Genius API info 
Client ID: r8BXdSiDmw9qfMoxh2S3f1g4AtvDaPf8XD-TWjkO77sc_hvsglOutM9Pl67I67Tr
Client Secret : pvEdzTUfKqtLbjv0qdxBJrqs5Hj1JQlhf4ICcQPWp3Zfo5j7uO88_34UWDbmT5a38wZP9lrTksDX4r8csgZsVA
Client Access Token: BoaVCPyQtW90wUPpm3lPVgm1b5AJGB0BIBvG1UO9dj473mlajOuyvJ1hrN0Dvw9G
Nickname : Luke5pika

```{r}

# This code chunk is for setting up access and web-scraping song info from the Spotify API

library(httr)
library(jsonlite)
library(rvest)
library(stringr)
library(xml2)

# Genius API Token
genius_token <- "BoaVCPyQtW90wUPpm3lPVgm1b5AJGB0BIBvG1UO9dj473mlajOuyvJ1hrN0Dvw9G" 
# Test song
test_title <- "Blinding Lights"
test_artist <- "The Weeknd"

# Function to search Genius for lyrics of given songs
# inputs: title of song, artist of song, and a given Genius token
# outputs: A url to the Genius page containing the lyrics of the song, as well as the lyrics themselves
search_song <- function(title, artist, token) {
  query <- URLencode(paste(title, artist))
  url <- paste0("https://api.genius.com/search?q=", query)
  res <- GET(url, add_headers(Authorization = paste("Bearer", token)))

  if (status_code(res) == 200) {
    json <- fromJSON(content(res, as = "text"), simplifyVector = FALSE)
    hits <- json$response$hits

    for (hit in hits) {
      result <- hit[["result"]]
      if (!is.null(result)) {
        primary_artist <- result[["primary_artist"]]
        artist_name <- primary_artist[["name"]]

        if (!is.null(artist_name) && grepl(tolower(artist), tolower(artist_name))) {
          return(result[["url"]])
        }
      }
    }
  } else {
    warning("API request failed with status code: ", status_code(res))
  }

  return(NA)
}

#Function to get lyrics
#Inputs: Genius URL
#Outputs: cleaned up lyrics as one line
get_clean_lyrics <- function(url) {
  page <- read_html(url)
  lyrics_nodes <- html_elements(page, '[data-lyrics-container="true"]')

  if (length(lyrics_nodes) == 0) {
    lyrics_nodes <- html_elements(page, 'div.lyrics')  # fallback
  }

  # Collapse all the lyrics text with line breaks between nodes
  lyrics <- lyrics_nodes %>%
    html_text2() %>%  # html_text2() preserves line breaks better
    paste(collapse = "\n")
  
  lyrics <- sub("^.*?\\s[Ll]yrics\\s*", "", lyrics)
  lyrics <- sub(".*… Read More ", "", lyrics)
  
  # Keep only content after [Intro] or [Verse 1]
  lyrics_after <- sub(".*\\[.*?\\]", "", lyrics, ignore.case = TRUE)

  if (identical(lyrics_after, lyrics)) {
    lines <- strsplit(lyrics, "\n")[[1]]
    lines <- trimws(lines)
    # Look for first line that likely begins real lyrics (e.g., lowercase or punctuation)
    start_idx <- which(grepl("^[a-z]|[[:punct:]]", lines))[1]
    if (!is.na(start_idx)) {
      lyrics_after <- paste(lines[start_idx:length(lines)], collapse = "\n")
    }
  }
  
  # Remove all [Section Headers]
  clean_lyrics <- str_replace_all(lyrics_after, "\\[.*?\\]", "")
  # Trim and fix spacing
  clean_lyrics <- gsub("\\s+", " ", clean_lyrics)
  
  clean_lyrics <- gsub("([a-z])([A-Z])", "\\1 \\2", clean_lyrics)
  clean_lyrics <- gsub("(\\w)\\(", "\\1 (", clean_lyrics)
  clean_lyrics <- gsub("\\)(\\w)", ") \\1", clean_lyrics)
  clean_lyrics <- gsub("([\\)\\?\\!\\.,])(?=\\w)", "\\1 ", clean_lyrics, perl = TRUE)
  clean_lyrics <- gsub('\\"', '', clean_lyrics)
  return(clean_lyrics)
}

```
In order to format the lyrics in an easy to use way, certain things that were scraped from the Genius website had to be removed, for example, messages marking the start of a new verse or chorus were present and are not a part of the actual lyrics so they had to be removed. Another problem that we ran into was a formatting issues when the lyrics started a new line on Genius. When this happened, a space was not present between the end of the first line and the start of the second. Other issues included trouble when special characters or punctuation were present. In order to fix all of these issues to make the 'get_clean_lyrics()' function as universal as possible, the best method we found was to tackle the problems one at a time and continually test a variety of songs to make sure the lyrics of each came out clean and usable for future analysis. 

To gather all the songs that were billboard top 100 hits, we found Wikipedia links that gathered the ‘top 100 number 1 singles’ by decades from 1958 to present day, grouping 1958 to 1969, the 1970s, 1980s, etc. From those links we scraped the artist, title, and date of the songs. We had some struggle keeping the row for the dates of the songs but eventually found something clever that worked. 

For gathering the genius URL and lyrics for all the songs we had to first gather a genius API token to be able to access the genius website. Once we had that, we created a function called ‘search_song’ which would take the artist, name of the song, and genius token which would give out the URL and lyrics of the song back to us. From there we created a function called ‘get_lyrics_clean’ which would then take the genius URL and give back a cleaned-up (getting rid of the weird formatting and extra labels of the lyrics from genius) version of the lyrics in one line. 

To create the table which included artists, song, date, genius URL, and lyrics we created a function called ‘process_batch’ which took the song, scraped the genius URL of the song, and then put the lyrics of the song through the ‘get_clean_lyrics’ function for all 1,185 songs. Running this took a long time, so we decided that instead of everyone having to run the code, we would turn the table into a csv file and call the csv file when we needed it. 

## Section 2

```{r Cole Umland}
#This table is cleaned up and ready to roll.
library(rvest)
library(dplyr)
library(purrr)
library(stringr)

decade_urls <- c(
  "https://en.wikipedia.org/wiki/List_of_Billboard_Hot_100_number-one_singles_from_1958_to_1969",
  "https://en.wikipedia.org/wiki/List_of_Billboard_Hot_100_number-one_singles_of_the_1970s",
  "https://en.wikipedia.org/wiki/List_of_Billboard_Hot_100_number-one_singles_of_the_1980s",
  "https://en.wikipedia.org/wiki/List_of_Billboard_Hot_100_number-one_singles_of_the_1990s",
  "https://en.wikipedia.org/wiki/List_of_Billboard_Hot_100_number-one_singles_of_the_2000s",
  "https://en.wikipedia.org/wiki/List_of_Billboard_Hot_100_number-one_singles_of_the_2010s",
  "https://en.wikipedia.org/wiki/List_of_Billboard_Hot_100_number-one_singles_of_the_2020s"
)

all_number_ones <- map_df(decade_urls, function(url) {
  page <- read_html(url)

  table <- page %>%
    html_node("table.wikitable") %>%
    html_table(fill = TRUE)

  names(table) <- tolower(names(table))

  if (any(str_detect(names(table), "single|song")) && any(str_detect(names(table), "artist"))) {
    cleaned <- table %>%
      select(contains("single"), contains("artist"), contains("reached")) %>%
      rename_with(~ c("single", "artist", "date")[1:length(.)]) %>%
      # Remove rows with all values that have four characters
      #Clever, ran into the problem where deleting rows with only four characters also deleted songs with years titles (ex: "1999"). Fixed this by changing any to all in the following code line. All rows with years in every column are now deleted
      filter(!apply(., 1, function(row) all(nchar(as.character(row)) == 4)))
    return(cleaned)
  } else {
    return(NULL)
  }
})

```

## Section 3 

```{r, eval=FALSE}

library(tidyverse)

clean_strings <- function(string) {
  string <- tolower(string)
  string <- gsub("&", " and ", string)
  string <- gsub("\\([^)]*\\)", "", string)
  
  # Remove "featuring", "feat.", etc. at end or within string
  string <- gsub("featuring.*", "", string)
  string <- gsub("feat\\..*", "", string)
  string <- gsub("feat .*", "", string)
  
  string <- gsub("[[:punct:]]", "", string)
  string <- gsub("\\s+", "-", string)
  string <- gsub("-+", "-", string)
  string <- gsub("^-|-$", "", string)
  return(string)
}


process_batch_combined <- function(data, start_row, end_row, token, output_file) {
  results <- list()
  
  for (i in start_row:end_row) {
    song <- data[i, ]
    cat("Processing [", i, "]: ", song$single, " by ", song$artist, "\n")

    # First attempt using raw artist/title
    url <- tryCatch(search_song(song$single, song$artist, token), error = function(e) NA)
    Sys.sleep(0.5)

    lyrics <- if (!is.na(url)) tryCatch(get_clean_lyrics(url), error = function(e) NA) else NA
    Sys.sleep(0.5)

    # Defaults
    clean_title <- NA
    clean_artist <- NA
    constructed_url <- NA
    method_used <- "original"

    # Fallback if first attempt fails
    if (is.na(lyrics)) {
      clean_title <- clean_strings(as.character(song$single))
      clean_artist <- clean_strings(as.character(song$artist))

      constructed_url <- paste0("https://genius.com/", clean_artist, "-", clean_title, "-lyrics")
      cat("First attempt failed. Trying constructed Genius URL: ", constructed_url, "\n")

      lyrics <- if (is.na(url)) tryCatch(get_clean_lyrics(constructed_url), error = function(e) NA) else NA
      Sys.sleep(0.5)

      method_used <- "cleaned"
    }

   results[[length(results) + 1]] <- tibble(
      artist = song$artist,
      single = song$single,
      clean_artist = clean_artist,
      clean_single = clean_title,
      attempted_url = constructed_url,
      genius_url = url,
      method = method_used,
      lyrics = lyrics
    )
  }

  # Write all results at once after the loop
  result_tbl <- bind_rows(results)
  write_csv(result_tbl, output_file, append = file.exists(output_file))
}


# output_file <- "final_lyrics_output.csv"
# start_index <- 1
# end_index <- 1185

# Optional: skip already processed
# if (file.exists(output_file)) {
#   music <- read_csv(output_file, show_col_types = FALSE)
#   start_index <- nrow(music) + 1
# }
# 
# if (start_index <= nrow(all_number_ones)) {
#   process_batch_combined(all_number_ones, start_index, min(end_index, nrow(all_number_ones)), genius_token, output_file)
# } else {
#   cat("All songs already processed.\n")
# }


```
#Section 3.1 Reprocessing CSV after first attempt failed after number 915
```{r}
temporary_file <- read_csv("final_lyrics_output.csv")

trimmed_file <- temporary_file %>% slice(1:915)

write_csv(trimmed_file, "lyrics_output_trimmed.csv")

begin <- 916
end <- 1185
output_file <- "reprocessed_lyrics_output.csv"

process_batch_combined(all_number_ones, begin, end, genius_token, output_file)
```

#Section 3.2 Combining CSVs into one final file
```{r}
cleaned <- read_csv("lyrics_output_trimmed.csv")
reprocessed <- read_csv("reprocessed_lyrics_output.csv")

final <- bind_rows(cleaned, reprocessed)
write_csv(final, "hopeful.csv")
```

#Section 3.3 Reading in the Data Frame
```{r}
lyrics_df <- read.csv("hopeful.csv")
```

##Section 4 Cole Umland
```{r, echo=FALSE}
# Count how many times the title appears in the lyrics (case-insensitive)
count_title_repeats <- function(title, lyrics) {
  if (is.na(lyrics) || lyrics == "") {
    return(NA)
  }
  
  # Normalize title and lyrics: lowercase, remove punctuation
  clean_title <- tolower(gsub("[[:punct:]]", "", title))
  clean_lyrics <- tolower(gsub("[[:punct:]]", "", lyrics))
  
  # Split lyrics into words and match title
  title_words <- strsplit(clean_title, "\\s+")[[1]]
  pattern <- paste0("\\b", paste(title_words, collapse = "\\s+"), "\\b")
  
  # Count matches
  match_count <- str_count(clean_lyrics, regex(pattern, ignore_case = TRUE))
  return(match_count)
}

cat("Title repets in Blinding Lights:\n")
title <- "Blinding Lights"
lyrics <- get_clean_lyrics(search_song(title, "The Weeknd", genius_token))
count_title_repeats(title, lyrics)

cat("Title repeats in Shake Tt Off:\n")
title <- "Shake It Off"
artist <- "Taylor Swift"
url <- search_song(title, artist, genius_token)
lyrics <- get_clean_lyrics(url)
count_title_repeats(title, lyrics)
```
  Initially, in our test for title repetitiveness we noticed the drastic disparities between title examples. Some songs, such as "Blinding Lights" by The Weekend seem to have no title repetitions in the lyrics. This although isn't the necessarily the case as the words "blinded," and "lights" are in the song, just not exactly as in the title. In contrast, songs like "Shake It Off," by Taylor Swift explicitly state the title in their lyrics. Realizing this, we were led to try more sophisticated repetitive tests to see when titles were included in song lyrics. The two methods we used to test for title repetitiveness in the song lyrics were the fuzzy method and the Stem method.

The Fuzzy Method

Knowing that some songs had soft title repetitions and some songs had explicit repetitions, we wanted to create a test that counted explicit repetitions with some leeway. This way, songs that had their title in their lyrics, but in just a little different of a format, would be counted as a repetition. 

To determine how close the title had to be in the lyrics to count as a repetition, we created an arbitrary distance called "max_distance." Anything in the lyrics that was close enough to the title, was then counted as a repetition. How we determined this distance was through trail and error. The small the max distance value (e.g. 0), the more exact the lyrics had to be to the title to be counted as a repetition. In the case of a max distance of zero, only exact repetitions were allowed to count as repeats. The larger the max distance (e.g. 10), the more typos and differences were allowed to be counted as a title repetition. We tested higher and lower max distance values. In this process, we discovered that songs with short titles were picking up more title repeats coupled with larger max distances. This is because the shorter the title, the easier it would be for any word with a certain amount of typos to match with it. We settled on a max distance of five by testing certain examples of both high and low repetitiveness directly with their lyrics from Genius to see how accurate the test was. 

In the end, decided to determine the max distance based on the character count in the title of each single. This was to directly combat a static max distance and the impact it had on miscounting songs with short titles. If the title has four or less characters, there can be no typos for it to count as a as a repeat. For songs with 7 or less characters, we set a max distance of 2, and for everything else, a max distance of 4.

## Section 5 Cole Umland
```{r, message=FALSE}
library(dplyr)
library(purrr)
library(stringdist)

count_fuzzy_title_repeats <- function(title, lyrics_text, max_distance = NULL, ngram_window = 5) {
  if (is.na(lyrics_text) || is.null(lyrics_text)) return(NA)
  
  # Preprocess: lowercase
  lyrics_text <- tolower(lyrics_text)
  title <- tolower(title)
  
  # Dynamically set max_distance based on title character length
  if (is.null(max_distance)) {
    title_length <- nchar(title)
   max_distance <- if (title_length <= 4) { 0 } else if (title_length <= 7) { 2 } else { 4 }
}
  
  # Split lyrics into words
  words <- unlist(strsplit(lyrics_text, "\\s+"))
  title_len <- length(strsplit(title, "\\s+")[[1]])
  ngram_size <- max(title_len, 1)

  if (length(words) < ngram_size) return(0)

  # Create n-grams
  ngrams <- sapply(1:(length(words) - ngram_size + 1), function(i) {
    paste(words[i:(i + ngram_size - 1)], collapse = " ")
  })

  # Compute distances
  distances <- stringdist::stringdist(ngrams, title, method = "lv")

  # Count matches
  sum(distances <= max_distance, na.rm = TRUE)
}

##########
# Apply fuzzy matching directly using mutate + map2
#Eventually, we need to apply this to our prefect table and not processed
lyrics_df <- lyrics_df %>%
  mutate(
    fuzzy_repeats = map2_int(single, lyrics, ~ tryCatch(
      count_fuzzy_title_repeats(.x, .y, max_distance = NULL),
      error = function(e) NA
    ))
  )
# View songs with high repetition
#This reads the top songs with higher repetition first, and the rest in descending order. May not be needed in the future
lyrics_df %>% arrange(desc(fuzzy_repeats)) %>% head(10)

# View results
head(lyrics_df)
```

##Section 5.1 Cole Umland
```{r}
library(ggplot2)
library(dplyr)
library(stringr)
library(lubridate)

# Custom function to expand 2-digit years
#This breaks the string into three parts
expand_year <- function(date_str) {
  parts <- unlist(strsplit(date_str, "-"))
  year_2digit <- as.integer(parts[3])
  
  # Determine full year based on cutoff
  # We ran into the problem of the year column creation on either side of the 21st century when making the new column. This logic fixed our issue
  full_year <- ifelse(year_2digit <= 25, 2000 + year_2digit, 1900 + year_2digit)
  
  # Rebuild date string
  paste(parts[1], parts[2], full_year, sep = "-")
}

# Apply fix to data frame
lyrics_df <- lyrics_df %>%
  mutate(
    date_fixed = sapply(date, expand_year),
    parsed_date = dmy(date_fixed),
    year = year(parsed_date)
  )

# This groups all the entries from the lyrics_df with the same entry in the year column. Then a yearly summary is made for every year. 
#Noticing the plot the first time, the years with more number one songs seemed to have more total repeats. This was more likely due to more songs totaling more repeats together. To normalize this, we took the total title repeats and divided it by the amount of #1 songs in that year. This normalized each year.

yearly_normalized <- lyrics_df %>%
  group_by(year) %>%
  summarise(
    total_repeats = sum(fuzzy_repeats, na.rm = TRUE),
    song_count = n(),
    avg_repeats = total_repeats / song_count
  )

fuzzy_gg <- ggplot(yearly_normalized, aes(x = year, y = avg_repeats)) +
  geom_line(color = "steelblue") +
  geom_point(color = "darkred") +
  geom_smooth(color = "orange", size = 1) +
  labs(
    title = "Fuzzy Repeats by Year: Fuzzy",
    x = "Year",
    y = "Fuzzy Repeats per Year"
  ) +
  theme_minimal()

print(fuzzy_gg)
```


## Section 6

The below code chunk creates a function that ultimately gets a 'unique word percentage' from the lyrics of each song. It does this by counting the total number of words, counting the number of unique words, and then dividing those counts to get the percentage. A lower percentage means a song is more repetitive while a higher 'unique word percentage' means a song is more unique and less repetitive. 

```{r}
get_unique_word_percentage_from_text_but_now_repetitive_percentage_from_text <- function(lyrics) {
  if (is.na(lyrics) || lyrics == "") {
    return(tibble(
      total_words = NA_integer_,
      unique_words = NA_integer_,
      repetitive_percentage = NA_real_
    ))
  }

  words <- str_to_lower(lyrics) %>%
    str_replace_all("[^a-z\\s']", "") %>%  # keeps apostrophes like in "don't"
    str_split("\\s+") %>%
    unlist() %>%
    discard(~ .x == "")

  total_words <- length(words)
  unique_words <- length(unique(words))

  if (total_words == 0) {
    return(tibble(total_words = 0, unique_words = 0, repetitive_percentage = NA_real_))
  }

  tibble(
    total_words = total_words,
    unique_words = unique_words,
    repetitive_percentage = round((1 - (unique_words / total_words)), 4)
  )
}

lyrics_df <- lyrics_df %>%
  mutate(stats = map(lyrics, get_unique_word_percentage_from_text_but_now_repetitive_percentage_from_text)) %>%
  unnest(stats)
```

## Section 6.1

```{r}
avg_repetitiveness_by_year <- lyrics_df %>%
  group_by(year) %>%
  summarise(avg_repetitive_percentage = mean(repetitive_percentage, na.rm = TRUE))

ggplot(avg_repetitiveness_by_year, aes(x = year, y = avg_repetitive_percentage)) +
  geom_line(color = "steelblue", size = .7) +
  geom_point(color = "darkred", size = 2) +
  labs(
    title = "Average Song Repetitiveness by Year",
    x = "Year",
    y = "Average Repetitiveness Percentage"
  ) +
  theme_minimal()
```

#Section 7: Stemming
```{r}
library(SnowballC)
library(dplyr)
library(tidytext)
library(stringr)

get_top_stems <- function(lyrics_dat) {
  lyrics_dat %>%
    unnest_tokens(word, lyrics) %>%
    mutate(stem = wordStem(word, language = "en")) %>%
    count(single, stem, sort = TRUE, name = "frequency") %>%
    group_by(single) %>%
    mutate(
      total = sum(frequency),
      frequency_pct = round(100 * frequency / total, 2)
    ) %>%
    slice_max(order_by = frequency, n = 1, with_ties = FALSE) %>%
    ungroup() %>%
    transmute(
      single,
      top_stem = stem,
      frequency,
      frequency_pct
    )
}

top_stems <- get_top_stems(lyrics_df)

lyrics_df <- left_join(lyrics_df, top_stems, by = "single")
head(lyrics_df)

```
Another method we utilized to analyze the repetitiveness of the songs was by counting the number of similar words present in each song and looking at the percentage of each song's lyrics these similar words accounted for. The technique we used is called Stemming, in which each word is reduced to its root form or stem and then the number of these matching stems was analyzed. For example, 'run,' 'running,' and 'ran,' would all be reduced to just 'run' and then counted as three instances of this stem appearing in the lyrics of a song. The songs that have higher percentages of repeated stems are then seen as the more repetitive songs. 
#Section 7.1
```{r}
avg_stem_by_year <- lyrics_df %>%
  group_by(year) %>%
  summarize(frequency_pct = 
              mean(frequency_pct, na.rm = TRUE))


stem_gg <- ggplot(avg_stem_by_year, mapping = aes(x = year, y = frequency_pct)) +
  geom_line(color = "steelblue", size = .7) +
  geom_point(color = "darkred", size = 2) +
  geom_smooth(color = "orange", size = 1) +
  labs(
    title = "Stem Average by Year",
    x = "Year",
    y = "Stem Average"
  ) +
  theme_minimal()

print(stem_gg)
```


